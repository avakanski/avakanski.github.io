<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aleksandar Vakanski - [Research Topic]</title>
    <link href="../styles.css" rel="stylesheet" type="text/css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <script src="../script.js" defer></script>
    <script src="../nav.js" defer></script>
    
    <!-- Add UI-specific CSS for the footer -->
    <link rel="stylesheet" href="../ui-footer-styles.css">
</head>

<body>

<div class="container">

	<header>
		<div class="header-content">
			<h1>Aleksandar (Alex) Vakanski</h1>
			<a href="http://www.uidaho.edu/">
				<img src="../UI_logo.jpg" alt="University of Idaho logo" class="ui-logo">
			</a>
		</div>
	</header>
	
	<nav id="main-nav"></nav>

	<main>
	 <h3>Machine Learning-based Analysis of Breast Ultrasound Images</h3>
     <p>The project employs machine learning approaches for identification and segmentation of breast tumors in ultrasound images. 
     				This is a collaborative research project led by Dr. Min Xian from the Department of Computer Science at the University of Idaho. 
     				In general, medical image processing for automated cancer detection is challenging. 
     				In particular, breast ultrasound images are characterized by low contrast and low signal-to-noise ratio resulting in fuzzy borders of the tissue, 
     				substantial presence of image artifacts, and poor depth perception. </p>
     <p>One challenge that the project addresses is <b>tumor segmentation</b> in breast ultrasound images. Toward this goal, we considered incorporating topological and anatomical prior information into a deep learning model for image segmentation. Incorporating human expertise and domain knowledge is particularly important for medical image processing applications, marked with small datasets, and objects of interest in the form of organs or lesions not typically seen in traditional datasets. However, the incorporation of prior knowledge for breast tumor diagnosis is challenging, since shape, boundary, curvature, intensity, or other common medical priors vary significantly across patients and cannot be employed. In our work, we employed maps of visual saliency as prior image topology knowledge. Visual saliency refers to image maps that assign values to the pixels based on the ability to stand out and differentiate from the neighboring pixels. For instance, tumor regions in medical images have higher visual saliency and attract radiologists’ attention when examining images for breast cancer screening. We proposed a <a href="#6">deep learning model that integrates visual saliency</a> by using the attention mechanism. A U-Net architecture consisting of fully convolutional encoder and decoder sub-networks with skip connections was used for incorporating the prior knowledge in the form of a pyramid of visual saliency maps. The attention blocks are integrated with the layers of the encoder to force the network to learn feature representations that place spatial attention to target regions with high saliency values. Unlike similar deep learning models that introduce attention blocks by merging internal feature representations from different layers, the proposed approach employs external auxiliary inputs in the form of visual saliency maps for training the model parameters.</p>
	 <figure class="centered-figure">
    <img src="../Images/BreastCancer.jpg" style="height: 200px;" alt="Breast ultrasound image example">
    <figcaption>Figure: A breast ultrasound image, the segmented tumor in the image, and a 
    visual saliency map indicating the most salient regions in the image.</figcaption>
  </figure>

	<p>In other related works, we designed models for <b>segmentation of small-size tumors</b> in breast ultrasound images. Namely, detecting small tumors has been particularly difficult for recent machine learning models that have otherwise exhibited impressing performance in detecting large-size tumors. On the other hand, small tumors are critically important for finding early-stage cancers using computer-aided diagnosis, since early detection is the key to improving the survival rate. Toward this goal, our team developed 
	STAN (Small Tumor-Aware Network), which fuses image context information at different scales to achieve improved performance. </p>
	<figure class="centered-figure">
    <img src="../Images/STAN.png" style="height: 350px;" alt="STAN architecture">
    <figcaption>Figure: STAN architecture. The block sizes do not represent the actual feature maps.</figcaption>
  </figure>

	<p>Our team also conducted research on models for <b>classification</b> of breast ultrasound images. We studied the correlation between complexity measures and the generalization abilities of deep learning classifiers, and we found that PAC-Bayes flatness and path norm measures produce the most consistent explanation for the combination of models and data. Similarly, our lightweight multitask model EMT-Net is designed for simultaneous classification and segmentation of breast ultrasound images. The model employs a new numerically stable loss function that easily controls the balance between the sensitivity and specificity of cancer detection. </p>

	<p>We are also interested in enhancing the <b>explainability</b> of machine learning models for breast cancer detection. BI-RADS-Net incorporates tasks for explaining and classifying breast tumors, by learning feature representations relevant to clinical diagnosis. Explanations of the predictions (benign or malignant) are provided in terms of the BIRADS descriptors of shape, orientation, margin, echo pattern, and posterior features. Additionally, our approach predicts the likelihood of malignancy of the findings, which relates to the BI-RADS assessment category reported by clinicians.</p>
	<figure class="centered-figure">
    <img src="../Images/Bi-RADS-Net.png" style="height: 350px;" alt="BI-RADS-Net architecture">
    <figcaption>Figure: Network architecture of the proposed BI-RADS-Net for breast ultrasound computer-aided diagnosis</figcaption>
  </figure>

	<p>Another line of research of our group is directed toward <b>analysis and segmentation of histopathology images</b>. We proposed an approach that employs a bending loss regularization for separating overlapped nuclei in histopathology images. The bending loss applies high penalties to contour points with large curvature, to improve the segmentation of overlapped nuclei. Our team also designed TA-Net, which is a multitask learning model for gland segmentation, based on learning shared representation from two tasks: instance segmentation and gland topology estimation. Similarly, in another article we applied a GAN network to generate synthetic histopathology images. The model is dubbed Sharp-GAN, and it uses a sharpness loss regularized GAN for image synthesis. </p>
	<figure class="centered-figure">
    <img src="../Images/TA-Net.png" style="height: 350px;" alt="TA-Net architecture">
    <figcaption>Figure: TA-Net takes image patches as input and outputs the gland instance (INST) map and medial axis (MA) distance map. The Marker Map is generated using the MA map.</figcaption>
  </figure>

	
	<h3>Publications</h3>
	<ol>
		<li>Y. Ma, K. Lucke, M. Xian, and <b><strong>A. Vakanski</strong></b>, "Semantic-aware adaptive binary search for hard-label black-box attack," <em>Computers</em>, vol. 13, no. 8, pp. 1–14, Aug. 2024. [DOI: <a href="https://doi.org/10.3390/computers13080203">10.3390/computers13080203</a>] [<a href="../Articles/ref_Ma2024.tex">Bibtex</a>] [<a href="https://www.mdpi.com/2073-431X/13/8/203">MDPI Computers</a>]&nbsp;<a href="../Articles/Ma_(2024)_Semantic_aware_adaptive_binary_search_for_black_box_attack.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>H. Wang, <b><strong>A. Vakanski</strong></b>, C. Shi, and M. Xian, "Bend-Net: Bending loss regularized multitask learning network for nuclei segmentation in histopathology images," <em>Information</em>, vol. 15, no. 417, pp. 1–15, Jul. 2024. [DOI: <a href="https://doi.org/10.3390/info15070417">10.3390/info15070417</a>] [<a href="../Articles/ref_Wang2024.tex">Bibtex</a>] [<a href="https://www.mdpi.com/2078-2489/15/7/417">MDPI Information</a>]&nbsp;<a href="../Articles/Wang_(2024)_Bend-Net,_Bending_Loss_Network_for_Histopathology_Images.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>K. Lucke,  <b><strong>A. Vakanski</strong></b>, and M. Xian, "A2DMN: Anatomy-aware dilated multiscale network for breast ultrasound semantic segmentation," in <em>Proceedings of the International Symposium on Biomedical Imaging (ISBI 2024)</em>, Athens, Greece, pp. 1-5, 2024.</li>
		<li>B. Zhang, <b><strong>A. Vakanski</strong></b> and M. Xian, "BI-RADS-NET-V2: A composite multi-task neural network for computer-aided diagnosis of breast cancer in ultrasound images with semantic and quantitative explanations," <em>IEEE Access</em>, vol. 11, pp. 79480–79494, Jul. 2023. [DOI: <a href="https://doi.org/10.1109/ACCESS.2023.3298569">10.1109/ACCESS.2023.3298569</a>] [<a href="../Articles/ref_Zhang2023.tex">Bibtex</a>] [<a href="https://ieeexplore.ieee.org/document/10193749">IEEE Explore</a>]&nbsp;<a href="../Articles/Zhang_et_al_(2023)_BI-RADS-NET-V2_A_Composite_Multi-Task_NN_for_CAD_of_Breast_Cancer.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>M. Karimzadeh, <b><strong>A. Vakanski</strong></b>, M. Xian, and B. Zhang, "Post-hoc explainability of BI-RADS descriptors in a multi-task framework for breast cancer detection and segmentation," in <em>Proceedings of the 33rd IEEE International Workshop on Machine Learning and Signal Processing (MLSP 2023)</em>, Rome, Italy, pp. 1-6, 2023. [DOI: <a href="https://doi.org/10.1109/MLSP55844.2023.10286006">10.1109/MLSP55844.2023.10286006</a>] [<a href="../Articles/ref_Karimzadeh2023.tex">BibTex</a>] [<a href="https://ieeexplore.ieee.org/document/10286006">IEEE Explore</a>]&nbsp;<a href=../Articles/Karimzadeh_et_al_(2023)_Post-hoc_explainability_with_MT-BI-RADS.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>B. Shareef,  M. Xian, <b><strong>A. Vakanski</strong></b>, and H. Wang, "Breast ultrasound tumor classification using a hybrid multitask CNN-transformer network," in <em>Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2023)</em>, Vancouver, Canada, pp. 344-353, 2023. [DOI: <a href="https://doi.org/10.1007/978-3-031-43901-8_33">10.1007/978-3-031-43901-8_33</a>] [<a href="../Articles/ref_Shareef2023.tex">BibTex</a>] [<a href="https://link.springer.com/chapter/10.1007/978-3-031-43901-8_33">Springer Link</a>]&nbsp;<a href="../Articles/Shareef_et_al_(2023)_BUS_Tumor_Classification_using_a_Hybrid_MT_CNN_Transformer.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>H. Wang,  M. Xian, <b><strong>A. Vakanski</strong></b>, and B. Shareef, "SIAN: Style-guided instance-adaptive normalization for multi-organ histopathology image synthesis," in <em>Proceedings of the International Symposium on Biomedical Imaging (ISBI 2023)</em>, Cartagena de Indias, Colombia, pp. 1-5, 2023. [DOI: <a href="https://doi.org/10.1109/ISBI53787.2023.10230507">10.1109/ISBI53787.2023.10230507</a>] </li>
		<li>S. Butte,  H. Wang, <b><strong>A. Vakanski</strong></b>, and M. Xian, "Enhanced Sharp-GAN for histopathology image synthesis," in <em>Proceedings of the International Symposium on Biomedical Imaging (ISBI 2023)</em>, Cartagena de Indias, Colombia, pp. 1-5, 2023. [DOI: <a href="https://doi.org/10.1109/ISBI53787.2023.10230516">10.1109/ISBI53787.2023.10230516</a>] </li>
		<li>B. Shareef, <b><strong>A. Vakanski</strong></b>, P. E. Freer, and M. Xian, "ESTAN: Enhanced small tumor-aware network for breast ultrasound image segmentation," <em>Healthcare</em>, vol. 10, no. 11, pp. 1–14, Nov. 2022. [DOI: <a href=" https://doi.org/10.3390/healthcare10112262">10.3390/healthcare10112262</a>] [<a href="../Articles/ref_Shareef2022.tex">Bibtex</a>] [<a href="https://www.mdpi.com/2227-9032/10/11/2262">MDPI Healthcare</a>]&nbsp;<a href="../Articles/Shareef_et_al(2022)_ESTAN_Enhanced_Small_Tumor-Aware_Network_for_BUS_Segmentation.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>S. Sun,  M. Xian, <b><strong>A. Vakanski</strong></b>, and H. Ghanem, "MIRST-DM: Multi-instance RST with Drop-Max Layer for Robust Classification of Breast Cancer," in <em>Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2022)</em>, Singapore, Singapore, pp. 401-410, 2022. [DOI: <a href="https://doi.org/10.1007/978-3-031-16440-8_39">10.1007/978-3-031-16440-8_39</a>] [<a href="../Articles/ref_Sun2022.tex">BibTex</a>] [<a href="https://link.springer.com/chapter/10.1007/978-3-031-16440-8_39">Springer Link</a>]&nbsp;<a href="../Articles/Sun_et_al_(2022)_MIRST-DM_Mutliinstance_RST_with_Dropmax_Layer_for_BUS.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>J. Shi, <b><strong>A. Vakanski</strong></b>, M. Xian, J. Ding, and C. Ning, "EMT-Net: Efficient multitask network for computer-aided diagnosis of breast cancer," in <em>Proceedings of the International Symposium on Biomedical Imaging (ISBI 2022)</em>, Kolkata, India, pp. 1-5, 2022. [DOI: <a href="https://doi.org/10.1109/ISBI52829.2022.9761438">10.1109/ISBI52829.2022.9761438</a>] [PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9074851/">PMC9074851</a>] [<a href="../Articles/ref_Shi2022.tex">BibTex</a>] [<a href="https://ieeexplore.ieee.org/abstract/document/9761438">IEEE Explore</a>]&nbsp;<a href="../Articles/Shi_et_al_(2022)_EMT-NET_efficient_multitask_network_for_breast_cancer.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>S. Butte, H. Wang, M. Xian, and <b><strong>A. Vakanski</strong></b>, "Sharp-GAN: Sharpness loss regularized GAN for histopathology image synthesis," in <em>Proceedings of the International Symposium on Biomedical Imaging (ISBI 2022)</em>, Kolkata, India, pp. 1-5, 2022. [DOI: <a href="https://doi.org/10.1109/ISBI52829.2022.9761534">10.1109/ISBI52829.2022.9761534</a>] [PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9074846/">PMC9074846</a>] [<a href="../Articles/ref_Butte2022.tex">BibTex</a>] [<a href="https://ieeexplore.ieee.org/abstract/document/9761534">IEEE Explore</a>]&nbsp;<a href="../Articles/Butte_et_al_(2021)_SHARP-GAN_sharpness_loss_regularized_GAN_for_histopathology.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>H. Wang, M. Xian, and <b><strong>A. Vakanski</strong></b>, "TA-Net: Topology-aware network for gland segmentation," in <em>Proceedings of the Winter Conference on Applications of Computer Vision (WACV 2022)</em>, Waikoloa, USA, pp. 1556-1564, 2022. [PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9063467/">PMC9063467</a>] [<a href="../Articles/ref_Wang2022.tex">BibTex</a>] [<a href="https://openaccess.thecvf.com/content/WACV2022/html/Wang_TA-Net_Topology-Aware_Network_for_Gland_Segmentation_WACV_2022_paper.html">WACV 2022 Open Access</a>]&nbsp;<a href="../Articles/Wang_TA-Net_Topology-Aware_Network_for_Gland_Segmentation_WACV_2022_paper.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>B. Zhang, <b><strong>A. Vakanski</strong></b>, and M. Xian, "BI-RADS-Net: An explainable multitask learning approach for cancer diagnosis in breast ultrasound images," in <em>Proceedings of the 31st IEEE International Workshop on Machine Learning and Signal Processing (MLSP 2021)</em>, Gold Coast, Australia, pp. 1-6, 2021. [DOI: <a href="https://doi.org/10.1109/MLSP52302.2021.9596314">10.1109/MLSP52302.2021.9596314</a>] [<a href="../Articles/ref_Zhang2021.tex">BibTex</a>] [<a href="https://ieeexplore.ieee.org/document/9596314">IEEE Explore</a>]&nbsp;<a href="../Articles/Zhang%20et%20al%20(2021)%20-%20BI-RADS-Net,%20an%20explainable%20multitask%20learning%20approach%20for%20BUS%20images.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li><b><strong>A. Vakanski</strong></b>, and M. Xian, "Evaluation of complexity measures for deep learning generalization in medical image analysis," in <em>Proceedings of the 31st IEEE International Workshop on Machine Learning and Signal Processing (MLSP 2021)</em>, Gold Coast, Australia, pp. 1-6, 2021. [DOI: <a href="https://doi.org/10.1109/MLSP52302.2021.9596501">10.1109/MLSP52302.2021.9596501</a>] [<a href="../Articles/ref_Vakanski2021.tex">BibTex</a>] [<a href="https://ieeexplore.ieee.org/document/9596501">IEEE Explore</a>]&nbsp;<a href="../Articles/Vakanski_Xian_(2021)_Evaluation_of_Generalization_Measures_in_Medical_Images.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li id="6"><b><strong>A. Vakanski</strong></b>, M. Xian, and P. Freer, "Attention enriched deep learning model for breast tumor segmentation in ultrasound images," <em>Ultrasound in Medicine and Biology</em>, vol. 46, no. 10, pp. 2819–2833, Oct. 2020. [<a href="../Articles/ref_Vakanski2020.tex">Bibtex</a>] [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0301562920302878">Elsevier Science Direct</a>]&nbsp;<a href="../Articles/Vakanski%20et%20al%20(2020)%20-%20Attention-Enriched%20DL%20Model%20for%20Breast%20Tumor%20Segmentation.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>H. Wang, M. Xian, and <b><strong>A. Vakanski</strong></b>, "Bending loss regularized network for nuclei segmentation in histopathology images," in <em>Proceedings of the 17th IEEE International Symposium on Biomedical Imaging (ISBI 2020)</em>, Iowa City, USA, pp. 1-5, 2020. [DOI: <a href="https://doi.org/10.1109/ISBI45749.2020.9098611">10.1109/ISBI45749.2020.9098611</a>] [PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7733529/">PMC7733529</a>] [<a href="../Articles/ref_Wang2020.tex">BibTex</a>] [<a href="https://ieeexplore.ieee.org/abstract/document/9098611">IEEE Explore</a>] &nbsp;<a href="../Articles/Wang_et_al_(2020)_Bending_loss_regularized_network_for_nuclei_segmentation.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
		<li>B. Shareef, M. Xian, and <b><strong>A. Vakanski</strong></b>, "<a name="STAN:_Small_tumor-aware_network_for_breast_ultrasound_image_segmentation">STAN: Small tumor-aware network for breast ultrasound image segmentation</a>," in <em>Proceedings of 17th IEEE the International Symposium on Biomedical Imaging (ISBI 2020)</em>, Iowa City, USA, pp. 1-5, 2020. [DOI: <a href="https://doi.org/10.1109/ISBI45749.2020.9098691">10.1109/ISBI45749.2020.9098691</a>] [PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7733528/">PMC7733528</a>] [<a href="../Articles/ref_Shareef2020.tex">BibTex</a>] [<a href="https://ieeexplore.ieee.org/abstract/document/9098691">IEEE Explore</a>] &nbsp;<a href="../Articles/Shareef_et_al_(2020)_STAN_Small_tumor_aware_network_for_breast_segmentation.pdf"><img height="17" src="../Images/pdficon_small.gif" width="17" /></a></li>
	</ol>

	</main>
	<footer>
		<p>&copy; 2024 Aleksandar Vakanski. All rights reserved.</p>
	</footer>

</div>

</body>
</html>
