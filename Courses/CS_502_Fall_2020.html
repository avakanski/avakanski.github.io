<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS 502: Direct Studies: Adversarial Machine Learning</title>
    <link href="../styles.css" rel="stylesheet" type="text/css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <script src="../script.js" defer></script>
    <script src="../nav.js" defer></script>
</head>

<body>
    <div class="container">
        <header>
            <div class="header-content">
                <h1>Aleksandar (Alex) Vakanski</h1>
                <a href="http://www.uidaho.edu/">
                    <img src="../UI_logo.jpg" alt="University of Idaho logo" class="ui-logo">
                </a>
            </div>
        </header>

        <nav id="main-nav"></nav>

        <main>
            <div class="content-wrapper">
                <h2>CS 502: Direct Studies: Adversarial Machine Learning</h2>

                <h3>Course Syllabus</h3>
                <p><a href="Adversarial_Machine_Learning/Fall_2020/CS502_Adversarial_Machine_Learning_Syllabus.pdf">Syllabus</a></p>

                <h3>Course Description</h3>
                <p>The course introduces students to adversarial attacks and defenses on machine learning models. The particular focus is on adversarial examples in deep learning models, due to their prevalence in modern machine learning applications. Covered topics include evasion attacks against white-box and black-box machine learning models, data poisoning attacks, privacy attacks, defense strategies against common adversarial attacks, generative adversarial networks, and robust machine learning models. The course also provides an overview of explainable machine learning and self-supervised machine learning, with an emphasis on deep learning models.</p>

                <h3>Course Objectives</h3>
                <p>The objective is that upon the completion of the course the students should demonstrate the ability to:</p>
                <ol>
                    <li>Explain the different types of adversarial attacks against machine learning models.</li>
                    <li>Describe the approaches for improved robustness of machine learning models against adversarial attacks.</li>
                    <li>Implement adversarial attacks and defense methods against adversarial attacks on general-purpose image datasets and medical image datasets.</li>
                    <li>Understand the importance of explainability and self-supervised learning in machine learning.</li>
                </ol>

                <h3>Course Materials</h3>
                <p><strong>Textbook:</strong></p>
                <ul>
                    <li>There is no required textbook. The required readings for each week are listed in the Course Outline section of the Syllabus.</li>
                </ul>

                <h3>Topics</h3>
                <ul>
                    <li>Introduction to Adversarial Machine Learning (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_1_Introduction_to_Adversarial_Machine_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2020/Lecture_1_Introduction_to_Adversarial_Machine_Learning.pdf">pdf</a>)</li>
                    <li>Deep Learning Overview (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_2_Deep_Learning_Overview.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2020/Lecture_2_Deep_Learning_Overview.pdf">pdf</a>)</li>
                    <li>Mathematics for Machine Learning (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_4_Mathematics_for_Machine_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2020/Lecture_4_Mathematics_for_Machine_Learning.pdf">pdf</a>)</li>
                    <li>Adversarial Machine Learning in Medical Image Processing</li>
                    <li>Evasion Attacks against Machine Learning Models (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_6_Evasion_Attacks_against_ML_Models.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2020/Lecture_6_Evasion_Attacks_against_ML_Models.pdf">pdf</a>)</li>
                    <li>Data Poisoning Attacks and Defenses (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_8_Data_Poisoning_Attacks_and_Defenses.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2020/Lecture_8_Data_Poisoning_Attacks_and_Defenses.pdf">pdf</a>)</li>
                    <li>Generative Adversarial Networks for AML (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_10_Generative_Adversarial_Networks_for_AML.pdf">pdf</a>)</li>
                    <li>Privacy Attacks in Machine Learning</li>
                    <li>Defenses Against Adversarial Attacks (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_12_Defenses_against_Adversarial_Attacks.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2020/Lecture_12_Defenses_against_Adversarial_Attacks.pdf">pdf</a>)</li>
                    <li>Explainability in Machine Learning (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_14_Explainability_in_Machine_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2020/Lecture_14_Explainability_in_Machine_Learning.pdf">pdf</a>)</li>
                    <li>Self-supervised Learning (<a href="Adversarial_Machine_Learning/Fall_2020/Lecture_16_Self-supervised_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2020/Lecture_16_Self-supervised_Learning.pdf">pdf</a>)</li>
                </ul>

                <h3>Evaluation Procedure</h3>
                <p>This course is delivered in a hybrid method. The dates for class meetings are indicated in the Course Outline section. In preparation for the class meetings, the students are expected to read the papers listed as required reading in the Course Outline section.</p>

                <h3>Grading</h3>
                <table class="course-table">
                    <tr>
                        <td class="course-number" style="width: 250px;">Homework Assignments (4)</td>
                        <td>100 %</td>
                    </tr>
                </table>
            </div>
        </main>

        <footer>
            <p>&copy; 2024 Aleksandar Vakanski. All rights reserved.</p>
        </footer>
    </div>
</body>
</html>
