<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS 487/587: Adversarial Machine Learning</title>
    <link href="../styles.css" rel="stylesheet" type="text/css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <script src="../script.js" defer></script>
    <script src="../nav.js" defer></script>
</head>

<body>
    <div class="container">
        <header>
            <div class="header-content">
                <h1>Aleksandar (Alex) Vakanski</h1>
                <a href="http://www.uidaho.edu/">
                    <img src="../UI_logo.jpg" alt="University of Idaho logo" class="ui-logo">
                </a>
            </div>
        </header>

        <nav id="main-nav"></nav>

        <main>
            <div class="content-wrapper">
                <h2>CS 487/587: Adversarial Machine Learning</h2>

                <h3>Course Information</h3>
                <p><strong>Semester:</strong> Spring 2025 (January 6&nbsp; - May 
				9, 2025)</p>
                <p><strong>Credit Hours:</strong> 3</p>
                <p><strong>Instructor:</strong> Alex Vakanski</p>
                <p><strong>Office Hours:</strong> Friday 12 p.m. - 1 p.m. PT (Zoom link on Canvas)</p>

                <h3>Course Materials From Previous Years</h3>
                <p>Links: <a href="CS_502_Fall_2020.html">Fall 2020</a>, <a href="CS_504_Fall_2021.html">Fall 2021</a>, <a href="CS_504_Spring_2023.html">Spring 2023</a>, <a href="AML_Course_Spring_2024.html">Spring 2024</a></p>

                <h3>Course Syllabus</h3>
                <p><a href="Adversarial_Machine_Learning/Spring_2025/CS_487_587_Adversarial_Machine_Learning_Syllabus.pdf">Syllabus</a></p>

                <h3>Course Description</h3>
                <p>The course introduces students to adversarial attacks on machine learning models and defenses against the attacks. The particular focus is on adversarial attacks and adversarial examples in deep learning models, due to their prevalence in modern machine learning applications. Covered topics include evasion attacks targeting white-box and black-box machine learning models, data poisoning attacks, privacy attacks, jailbreak attacks on large language models, defense strategies against adversarial attacks, and robust machine learning models. The course also provides an overview of adversarial attacks against machine learning models used in cybersecurity applications, including malware detection and classification, network intrusion detection, spam filtering, URL detection, cyber-physical systems, and biometric systems.</p>

                <h3>Course Objectives</h3>
                <p>The objective is that upon the completion of the course the students should demonstrate the ability to:</p>
                <ol>
                    <li>Identify the vulnerabilities of machine learning models to various types of adversarial attacks.</li>
                    <li>Differentiate between adversarial evasion attacks in white-box and black-box settings and understand the principles of data poisoning attacks.</li> 
					<li>Explain the fundamentals of adversarial privacy attacks and outline privacy-preserving defense methods.</li>
					<li>Describe jailbreak attacks on large language models and propose corresponding mitigation methods.</li>
					<li>List common defense strategies against adversarial attacks and discuss approaches for improved robustness of machine learning models.</li>
					<li>Identify the unique characteristics of adversarial attacks on machine learning models in the cybersecurity domain.</li>
					<li>Implement adversarial attacks and defenses against conventional machine learning models and deep learning models.</li>
					<li>Evaluate the effectiveness of adversarial attacks against anomaly detection systems for network intrusion detection, machine learning malware classifiers, and anti-spam filtering models.</li>
					<li>Analyze the ethical and societal implications of adversarial attacks and defenses.</li> 
                </ol>

                <h3>Course Materials</h3>
                <p><strong>Textbook:</strong> There is no required textbook. The 
				reading materials for each week are listed in the Course Outline section of the Syllabus.</p>

                <h3>Topics</h3>
                <ul>
                    <li>Introduction to Adversarial Machine Learning (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_1_Introduction_to_Adversarial_Machine_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_1_Introduction_to_Adversarial_Machine_Learning.pdf">pdf</a>)</li>
                    <li>Deep Learning Overview (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_2_Deep_Learning_Overview.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_2_Deep_Learning_Overview.pdf">pdf</a>)</li>
                    <li>Mathematics for Machine Learning (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_3_Mathematics_for_Machine_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_3_Mathematics_for_Machine_Learning.pdf">pdf</a>)</li>
                    <li>Evasion Attacks against White-box Machine Learning Models (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_4_Evasion_Attacks_against_White-box_Models.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_4_Evasion_Attacks_against_White-box_Models.pdf">pdf</a>)</li>
                    <li>Evasion Attacks against Black-box Machine Learning Models (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_5_Evasion_Attacks_against_Black-box_Models.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_5_Evasion_Attacks_against_Black-box_Models.pdf">pdf</a>)</li>
                    <li>Adversarial Attacks against Large Language Models (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_6_Adversarial_Attacks_against_LLMs.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_6_Adversarial_Attacks_against_LLMs.pdf">pdf</a>)</li>
                    <li>Defenses Against Evasion Attacks (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_7_Defenses_against_Evasion_Attacks.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_7_Defenses_against_Evasion_Attacks.pdf">pdf</a>)</li>
                    <li>Poisoning Attacks against Machine Learning Models (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_8_Poisoning_Attacks.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_8_Poisoning_Attacks.pdf">pdf</a>)</li>
                    <li>Defenses against Poisoning Attacks (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_9_Defenses_against_Poisoning_Attacks.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_9_Defenses_against_Poisoning_Attacks.pdf">pdf</a>)</li>
                    <li>Adversarial ML in Cybersecurity: Network Intrusion Detection (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_10_AML_in_Network_Intrusion_Detection.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_10_AML_in_Network_Intrusion_Detection.pdf">pdf</a>)</li>
                    <li>Adversarial ML in Cybersecurity: Malware Detection and Classification (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_10_AML_in_Malware_Detection.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_10_AML_in_Malware_Detection.pdf">pdf</a>)</li>
                    <li>Adversarial ML in Cybersecurity: Spam Filtering, URL Detection, and Cyber-physical Systems (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_10_AML_in_Spam_Filtering_URL_Detection_Cyber_Physical_Systems.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_10_AML_in_Spam_Filtering_URL_Detection_Cyber_Physical_Systems.pdf">pdf</a>)</li>
                    <li>Privacy Attacks against Machine Learning Models (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_11_Privacy_Attacks_against_ML.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_11_Privacy_Attacks_against_ML.pdf">pdf</a>)</li>
                    <li>Defenses against Privacy Attacks (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_12_Defenses_against_Privacy_Attacks.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_12_Defenses_against_Privacy_Attacks.pdf">pdf</a>)</li>
                    <li>Explainability in Machine Learning (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_13_Explainability_in_ML.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_13_Explainability_in_ML.pdf">pdf</a>)</li>
                    <li>Bias and Fairness in Machine Learning (<a href="Adversarial_Machine_Learning/Spring_2025/Lecture_14_Bias_and_Fairness_in_ML.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Spring_2025/Lecture_14_Bias_and_Fairness_in_ML.pdf">pdf</a>)</li>
                </ul>

                <h3>Prerequisites</h3>
                <p>CS 212 Practical Python, or CS 477 Python for Machine Learning, or Instructor Permission</p>
                <p>Students are expected to have a basic understanding of linear algebra, probability and statistics, and machine learning concepts. Familiarity with neural networks and deep learning is recommended, but not required. A working knowledge of Python programming is required to complete the course assignments and the course project. Additionally, it is preferred that the students have a basic level of familiarity with at least one of the following machine learning libraries: TensorFlow, Keras, or PyTorch.  </p>

                <h3>Evaluation Procedure</h3>
                <table class="course-table">
                    <tr>
                        <td class="course-number" style="width: 250px;">Homework Assignments (5)</td>
                        <td>40 %</td>
                    </tr>
                    <tr>
                        <td class="course-number" style="width: 250px;">Quizzes (3)</td>
                        <td>30 %</td>
                    </tr>
                    <tr>
                        <td class="course-number" style="width: 250px;">Lecture Presentation</td>
                        <td>10 %</td>
                    </tr>
                    <tr>
                        <td class="course-number" style="width: 250px;">Course Project</td>
                        <td>10 %</td>
                    </tr>
                    <tr>
                        <td class="course-number" style="width: 250px;">Attendance and Participation</td>
                        <td>10 %</td>
                    </tr>
                </table>
            </div>
        </main>

        <footer>
            <p>&copy; 2024 Aleksandar Vakanski. All rights reserved.</p>
        </footer>
    </div>
</body>
</html>
