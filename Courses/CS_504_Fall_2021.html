<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS 404/504 Special Topics: Adversarial Machine Learning</title>
    <link href="../styles.css" rel="stylesheet" type="text/css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <script src="../script.js" defer></script>
    <script src="../nav.js" defer></script>
</head>

<body>
    <div class="container">
        <header>
            <div class="header-content">
                <h1>Aleksandar (Alex) Vakanski</h1>
                <a href="http://www.uidaho.edu/">
                    <img src="../UI_logo.jpg" alt="University of Idaho logo" class="ui-logo">
                </a>
            </div>
        </header>

        <nav id="main-nav"></nav>

        <main>
            <div class="content-wrapper">
                <h2>CS 404/504 Special Topics: Adversarial Machine Learning</h2>

                <p>Link to the course materials from previous years: <a href="CS_502_Fall_2020.html">Fall 2020</a></p>

                <h3>Course Syllabus</h3>
                <p><a href="Adversarial_Machine_Learning/Fall_2021/CS_404_504_Adversarial_Machine_Learning_Syllabus.pdf">Syllabus</a></p>

                <h3>Course Description</h3>
                <p>The course introduces students to adversarial attacks and defenses against machine learning models. The particular focus is on adversarial examples in deep learning models, due to their prevalence in modern machine learning applications. Covered topics include evasion attacks against white-box and black-box machine learning models, data poisoning attacks, privacy attacks, defense strategies against common adversarial attacks, generative adversarial networks, and robust machine learning models. The course also provides an overview of adversarial attacks against machine learning models used in cybersecurity applications, including malware detection and classification, network intrusion detection, spam filtering, URL detection, cyber-physical systems, and biometric systems.</p>

                <h3>Course Objectives</h3>
                <p>The objective is that upon the completion of the course the students should demonstrate the ability to:</p>
                <ol>
                    <li>Outline the different categories of adversarial attacks against machine learning models.</li>
                    <li>Describe common defense approaches for improved robustness of machine learning models against adversarial attacks.</li>
                    <li>Understand the basics of adversarial data privacy attacks and privacy-preserving defense methods.</li>
                    <li>Identify the unique characteristics of adversarial machine learning attacks in the cybersecurity domain.</li>
                    <li>Implement adversarial attacks and defenses against conventional machine learning models and deep learning models for image classification.</li>
                    <li>Implement adversarial attacks against anomaly detection systems for network intrusion detection.</li>
                </ol>

                <h3>Course Materials</h3>
                <p><strong>Textbook:</strong></p>
                <ul>
                    <li>There is no required textbook. The required readings for each week are listed in the Course Outline section of the Syllabus.</li>
                </ul>

                <h3>Topics</h3>
                <ul>
                    <li>Introduction to Adversarial Machine Learning (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_1_Introduction_to_Adversarial_Machine_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_1_Introduction_to_Adversarial_Machine_Learning.pdf">pdf</a>)</li>
                    <li>Deep Learning Overview (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_2_Deep_Learning_Overview.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_2_Deep_Learning_Overview.pdf">pdf</a>)</li>
                    <li>Mathematics for Machine Learning (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_3_Mathematics_for_Machine_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_3_Mathematics_for_Machine_Learning.pdf">pdf</a>)</li>
                    <li>Evasion Attacks against White-box Machine Learning Models (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_5_Evasion_Attacks_against_White-box_Models.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_5_Evasion_Attacks_against_White-box_Models.pdf">pdf</a>)</li>
                    <li>Evasion Attacks against Black-box Machine Learning Models (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_6_Evasion_Attacks_against_Black-box_Models.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_6_Evasion_Attacks_against_Black-box_Models.pdf">pdf</a>)</li>
                    <li>Generative Adversarial Networks for Adversarial ML (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_7_GANs_for_AML.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_7_GANs_for_AML.pdf">pdf</a>)</li>
                    <li>Defenses Against Evasion Attacks (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_8_Defenses_against_Evasion_Attacks.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_8_Defenses_against_Evasion_Attacks.pdf">pdf</a>)</li>
                    <li>Poisoning Attacks and Defenses (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_9_Poisoning_Attacks_and_Defenses.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_9_Poisoning_Attacks_and_Defenses.pdf">pdf</a>)</li>
                    <li>Adversarial ML in Cybersecurity: Malware Detection and Classification (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_10_AML_in_Malware_Detection.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_10_AML_in_Malware_Detection.pdf">pdf</a>)</li>
                    <li>Adversarial ML in Cybersecurity: Network Intrusion Detection (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_10_AML_in_Network_Intrusion_Detection.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_10_AML_in_Network_Intrusion_Detection.pdf">pdf</a>)</li>
                    <li>Adversarial ML in Cybersecurity: Spam Filtering and URL Detection (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_10_AML_in_Spam_Filtering_and_URL_Detection.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_10_AML_in_Spam_Filtering_and_URL_Detection.pdf">pdf</a>)</li>
                    <li>Adversarial ML in Cybersecurity: Cyber-physical and Biometric Systems (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_10_AML_in_Cyber-physical_and_Biometric_Systems.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_10_AML_in_Cyber-physical_and_Biometric_Systems.pdf">pdf</a>)</li>
                    <li>Privacy Attacks against Machine Learning Models (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_11_Privacy_Attacks_against_ML.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_11_Privacy_Attacks_against_ML.pdf">pdf</a>)</li>
                    <li>Defenses against Privacy Attacks (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_12_Defenses_against_Privacy_Attacks.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_12_Defenses_against_Privacy_Attacks.pdf">pdf</a>)</li>
                    <li>Adversarial Examples in Audio and Text Data (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_13_Adversarial_Examples_in_Audio_and_Text.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_13_Adversarial_Examples_in_Audio_and_Text.pdf">pdf</a>)</li>
                    <li>Explainability in Machine Learning (<a href="Adversarial_Machine_Learning/Fall_2021/Lecture_14_Explainability_in_Machine_Learning.pptx">ppt</a>, <a href="Adversarial_Machine_Learning/Fall_2021/Lecture_14_Explainability_in_Machine_Learning.pdf">pdf</a>)</li>
                </ul>

                <h3>Prerequisites</h3>
                <p>Instructor Permission Required</p>
                <p>Students are expected to have basic knowledge of linear algebra, probability and statistics, and machine learning concepts. Knowledge of neural networks and deep learning is recommended, but not required. Programming in Python is required for completing the course assignments and the project. Additionally, it is preferred that the students are familiar with at least one of the following machine learning libraries: TensorFlow, Keras, or PyTorch.</p>

                <h3>Assignments</h3>
                <ul>
                    <li><a href="Adversarial_Machine_Learning/Fall_2021/Assignment_1.pdf">Assignment 1</a> - white-box and black-box evasions attacks against deep learning-based classification models. Links to student solutions for <a href="https://github.com/Jacob-Friedberg/Adversarial_machine_learning_GTSRB">Part 1 (TensorFlow)</a>, <a href="https://github.com/AzadehNk/White-box-evasion-attacks-on-the-BelgiumTS-BTSC-dataset">Part 1 (PyTorch)</a>, <a href="https://github.com/Silence-JL/CS-504-Final-Project-Fall-2021">Part 2</a>.</li>
                    <li><a href="Adversarial_Machine_Learning/Fall_2021/Assignment_2.pdf">Assignment 2</a> - adversarial defenses for white-box evasions attacks against deep learning-based classification models. Student <a href="https://github.com/lotkey/Adversarial-Machine-Learning-Defenses">solution</a>.</li>
                    <li><a href="Adversarial_Machine_Learning/Fall_2021/Assignment_3.pdf">Assignment 3</a> - adversarial attacks against machine learning models in cybersecurity applications. Student <a href="https://github.com/NegaNexus/Adversarial-Machine-Learning-for-Cybersecurity-Applications">solution</a>.</li>
                </ul>

                <h3>Evaluation Procedure</h3>
                <table class="course-table">
                    <tr>
                        <td>Homework Assignments (3)</td>
                        <td>60%</td>
                    </tr>
                    <tr>
                        <td>Lecture Presentation</td>
                        <td>10%</td>
                    </tr>
                    <tr>
                        <td>Course Project</td>
                        <td>30%</td>
                    </tr>
                </table>
            </div>
        </main>

        <footer>
            <p>&copy; 2024 Aleksandar Vakanski. All rights reserved.</p>
        </footer>
    </div>
</body>
</html>
